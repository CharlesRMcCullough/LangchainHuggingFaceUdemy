{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T15:07:35.641632Z",
     "start_time": "2024-11-18T15:07:35.106178Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.messages import AIMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.documents import Document\n",
    "from langchain.chains import create_retrieval_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T15:05:26.912826Z",
     "start_time": "2024-11-18T15:05:26.911115Z"
    }
   },
   "outputs": [],
   "source": [
    "#load_dotenv()\n",
    "#os.environ[\"LANGCHAIN_API_KEY\"]=os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "#os.environ[\"LANGCHAIN_PROJECT\"]=os.getenv(\"LANGCHAIN_PROJECT\")\n",
    "#os.environ[\"LANGCHAIN_TRACKING_V2\"]=\"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOllama(\n",
    "    model=\"llama3.2:latest\",\n",
    "    temperture=0.7\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Gen AI App using Langchain\n",
    "This tutorial was orginially meant for OpenApi, but I converted to Ollama as we went."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Ingestion - scrape Langchain\n",
    "https://docs.smith.langchain.com/administration/tutorials/manage_spend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T15:05:33.425544Z",
     "start_time": "2024-11-18T15:05:33.244655Z"
    }
   },
   "outputs": [],
   "source": [
    "loader=WebBaseLoader(\"https://docs.smith.langchain.com/administration/tutorials/manage_spend\")\n",
    "\n",
    "docs=loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data -> text -> split -> embeed -> store in Vector DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T15:05:38.326426Z",
     "start_time": "2024-11-18T15:05:38.323869Z"
    }
   },
   "outputs": [],
   "source": [
    "text_splitter=RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "documents=text_splitter.split_documents(docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings=OllamaEmbeddings(model=\"nomic-embed-text:latest\")\n",
    "vectorstoredb=FAISS.from_documents(docs, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorstoredb.save_local(\"../Embeddings/simpleapp_index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query from a the vector db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Only use similarity search not LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is the purpose of the tutorial?\"\n",
    "result=vectorstoredb.similarity_search(query)\n",
    "result[0].page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=ChatPromptTemplate.from_template(\n",
    "   \"\"\"\n",
    "    Answser the following question based only on the provided context:\n",
    "    <context>\n",
    "    {context}\n",
    "    </context>\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_chain=create_stuff_documents_chain(llm, prompt)\n",
    "\n",
    "document_chain.invoke({\n",
    "    \"input\":\"What does this tutorial walk through?\",\n",
    "    \"context\":[Document(page_content=\"This tutorial walks through optimizing your spend on LangSmith. In it, we will learn how to optimize existing spend and prevent future overspend on a realistic real-world example. We will use an existing LangSmith organization with high usage. Concepts can be transferred to your own organization.\")]\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever=vectorstoredb.as_retriever()\n",
    "retrieval_chain=create_retrieval_chain(retriever, document_chain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response=retrieval_chain.invoke({\"input\":\"What does this tutorial walk through?\"})\n",
    "response['answer']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response['context']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LangchainEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
